{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daf602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img_rows, img_col = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape) \n",
    "print(test_images.shape) \n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_col, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_col, 1)\n",
    "input_shape = (img_rows, img_col, 1) \n",
    "\n",
    "# helper functions\n",
    "def show_min_max(array, i):\n",
    "  random_image = array[i]\n",
    "  print(random_image.min(), random_image.max())\n",
    "\n",
    "def plot_image(array, i, labels):\n",
    "  plt.imshow(np.squeeze(array[i]))\n",
    "  plt.title(\" Digit \" + str(labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "plot_image(train_images, 100, train_labels)\n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_images = train_images.astype('float32') \n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "\n",
    "plot_image(train_images, 100, train_labels)\n",
    "show_min_max(train_images, 100)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b2167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 9, 32)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 128)         36992     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                204832    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 574,602\n",
      "Trainable params: 574,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "938/938 [==============================] - 46s 48ms/step - loss: 0.1975 - accuracy: 0.9371 - val_loss: 0.0488 - val_accuracy: 0.9847\n",
      "Epoch 2/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.0399 - val_accuracy: 0.9870\n",
      "Epoch 3/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
      "Epoch 4/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0376 - accuracy: 0.9888 - val_loss: 0.0354 - val_accuracy: 0.9905\n",
      "Epoch 5/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
      "Epoch 6/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0304 - val_accuracy: 0.9919\n",
      "Epoch 7/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0294 - accuracy: 0.9918 - val_loss: 0.0245 - val_accuracy: 0.9930\n",
      "Epoch 8/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.0275 - val_accuracy: 0.9923\n",
      "Epoch 9/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0238 - val_accuracy: 0.9924\n",
      "Epoch 10/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.0264 - val_accuracy: 0.9919\n",
      "Epoch 11/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.0307 - val_accuracy: 0.9911\n",
      "Epoch 12/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.0251 - val_accuracy: 0.9940\n",
      "Epoch 13/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0247 - accuracy: 0.9934 - val_loss: 0.0392 - val_accuracy: 0.9915\n",
      "Epoch 14/15\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0265 - val_accuracy: 0.9923\n",
      "Epoch 15/15\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.0263 - accuracy: 0.9936 - val_loss: 0.0343 - val_accuracy: 0.9917\n",
      "\n",
      "Test accuracy: 0.9916999936103821\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "epochs = 15\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "# added this\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (1, 1)))\n",
    "model.add(Dropout(rate = 0.4))\n",
    "model.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size = 64, epochs = epochs, validation_data = (test_images, test_labels), shuffle = True)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef632174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
