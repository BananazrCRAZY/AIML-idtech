{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sduu9xile3dG"
   },
   "source": [
    "## Testing a Network\n",
    "\n",
    "\n",
    "Export your own models or use these ([densely connected](https://drive.google.com/file/d/1Lh52SRvSWSpKbOllblVDJnXnMwhPgBhZ/view?usp=sharing) and [convolutional](https://drive.google.com/file/d/1ko2XkaPHaQ6IS6JHF_ydSVZAxGIo1Qm6/view?usp=sharing)) to see some of these concepts demonstrated.\n",
    "\n",
    "Download [this](https://drive.google.com/file/d/1FDcz90j6a2adGd8eL0srRhIiIVcHsVoo/view?usp=sharing) image to run the test.\n",
    "\n",
    "\n",
    "You can also look at the example code at the end of this file for some hints for how to do different tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rSsYVW8Aevff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from PIL import Image,ImageChops \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in the original data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"MNIST data loaded\")\n",
    "\n",
    "# This will work for the models if you download them from the links above. \n",
    "# If you want to export your own models, use the name of them here instead. \n",
    "model_1 = tf.keras.models.load_model('my_model.h5')\n",
    "# model_2 = tf.keras.models.load_model('cnn_model.h5')\n",
    "\n",
    "def plot_image(array, i, labels):\n",
    "  plt.imshow(np.squeeze(array[i]))\n",
    "  plt.title(\" Digit \" + str(labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "def predict_image(model, x):\n",
    "  x = x.astype('float32')\n",
    "  x = x / 255.0\n",
    "\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  image_predict = model.predict(x)\n",
    "  print(\"Predicted Label: \", np.argmax(image_predict))\n",
    "\n",
    "  plt.imshow(np.squeeze(x))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    " \n",
    "  # uncomment this like if you want to see the array of predictions\n",
    "  # print(image_predict)\n",
    "  return image_predict\n",
    "\n",
    "\n",
    "def plot_value_array(predictions_array, true_label, h):\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
    "  plt.ylim([(-1*h), h])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI_ALXkCNfiI"
   },
   "source": [
    "Follow the instructions to run a prediction in the cell below\n",
    "\n",
    "<details>\n",
    "<summary>Final code: </summary>\n",
    "\n",
    "```\n",
    "path = \"test3w.jpg\"\n",
    "img = image.load_img(path, target_size=(28,28), color_mode = \"grayscale\")\n",
    "img_arr = image.img_to_array(img)\n",
    "arr = predict_image(model_1,  img_arr)\n",
    "plot_value_array(arr, 3, 1)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WmwePC3mNfRB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADl0lEQVR4nO3dO27UABhGURvIBhBpkEZkCVRsIWvOFqiyBFAkGhAbQMhUVAzz0DzsOz6nnRRurv6RPjkzTtM0AMv3au4HAA4jVogQK0SIFSLEChFihYg3x/zxu7evp4fN3aWeBVbvy8uv4cfP3+O2z46K9WFzN3x+2pznqYB/fHp8+e9nvgZDhFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIOOqHqdju8f3HuR9hFk/fnud+hFVxWSFCrBAhVogQK0SIFSLEChFihQg76xWU98i1bshL5LJChFghQqwQIVaIECtEiBUixAoRdtYzKO+odLisECFWiBArRIgVIsQKEWKFCNPNynkFrsNlhQixQoRYIUKsECFWiBArRIgVIuys7OT1v+VwWSFCrBAhVogQK0SIFSLEChFihQg7643b976qHbXDZYUIsUKEWCFCrBAhVogQK0SIFSLsrHH+7+96uKwQIVaIECtEiBUixAoRYoUIsUKEnfXGeV/1drisECFWiBArRIgVIsQKEWKFCNPNwnkFjr9cVogQK0SIFSLEChFihQixQoRYIcLOugCnbKlegVsPlxUixAoRYoUIsUKEWCFCrBAhVoiws16BHZVzcFkhQqwQIVaIECtEiBUixAoRYoUIO+sC2FI5hMsKEWKFCLFChFghQqwQIVaIECtE2FkPcOpvpNpROQeXFSLEChFihQixQoRYIUKsEGG6YadTZ6tdTFrHcVkhQqwQIVaIECtEiBUixAoRYoUIO+sB9u2B+7bIS26Vl2YLXQ6XFSLEChFihQixQoRYIUKsECFWiLCznoEtkmtwWSFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixmmaDv/jcfw+DMPXyz0OrN6HaZrut31wVKzAfHwNhgixQoRYIUKsECFWiBArRIgVIsQKEWKFiD+P/EMPmseIjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN only works when the background is dark\n",
    "path = \"test13.png\"\n",
    "img = image.load_img(path, target_size = (28, 28), color_mode = \"grayscale\")\n",
    "img_arr = image.img_to_array(img)\n",
    "arr = predict_image(model_1, img_arr)\n",
    "plot_value_array(arr, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbY9i9U5fqfS"
   },
   "source": [
    "## Test 1\n",
    "\n",
    "Download any of [these](https://drive.google.com/drive/folders/1P1p161W5SSt2wFh7W3Z7-6gFVsv7kVsW?usp=sharing) images. Run them through a convolutional network and a densely connected one. \n",
    "\n",
    "What differences do you notice about the output? Why do you think that is? What about a different image? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwFSCBLyG62g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6bnMRLtfZWP"
   },
   "source": [
    "## Test 2\n",
    "\n",
    "Try using numpy to create an array of random numbers to mirror pixels (0 to 255). Feed that into the model to see what predictions it makes. \n",
    "\n",
    "What does the network do with it? Does it have a prediction? This can help you understand what kinds of bias your network might have. \n",
    "\n",
    "Try 10 random generated arrays. Can you notice a trend? What about with 100? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoTZFMDqG7sA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1dR7TXCWgLf"
   },
   "source": [
    "## Test 3\n",
    "\n",
    "Download an image with more than one digit in it. \n",
    "\n",
    "What can you learn about the network from it? What if you change the numbers? or the position of the number in the image? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-7grrCMG8l_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WkAl3TZYE51"
   },
   "source": [
    "##Test 4\n",
    "\n",
    "You can also call images from the test or train datasets. Run some images from the original data through your networks. Look at the graph and compare how the networks operate on data that they are accostomed to. \n",
    "\n",
    "What does the output look like for these images? Can you write code to have it predict 10 random images? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZCMqRQbG9LY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jgdcVVMITqT"
   },
   "source": [
    "# New Section\n",
    "\n",
    "<details>\n",
    "<summary>Example code: </summary>\n",
    "\n",
    "```\n",
    "# Code to load an image called 'test3w.jpg'\n",
    "# To use a different image upload it and change the name here.\n",
    "path = \"test3w.jpg\"\n",
    "img = image.load_img(path, target_size=(28,28), color_mode = \"grayscale\")\n",
    "x = image.img_to_array(img)\n",
    "true_label = 3\n",
    "\n",
    "# Predicting the label using model_1.\n",
    "p_arr = predict_image(model_1, x)\n",
    "# This will plot the values on a graph. The last argument is the height of the y-axis.\n",
    "plot_value_array(p_arr, true_label, 1)\n",
    "\n",
    "# Displaying the 100th image from the original dataset\n",
    "plot_image(test_images, 100, test_labels)\n",
    "\n",
    "# Predicting the label using model_1 on an image from test_images\n",
    "img_loc = 100\n",
    "img = test_images[img_loc]\n",
    "x = image.img_to_array(img)\n",
    "p_arr = predict_image(model_1, x)\n",
    "true_label = test_labels[img_loc]\n",
    "plot_value_array(p_arr, true_label, 1)\n",
    "\n",
    "# Create an array of random numbers from 0 to 255 of size (28, 28, 1)\n",
    "x = np.random.randint(0, 255, (28, 28, 1) )\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8.3_testing_networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
